{
  "input": {
    "images": [
      {
        "name": "test_img.jpg",
        "image": "https://pic.imgdd.cc/item/69071860c1e67097311264a1.jpg"
      }
    ],
    "videos": [
      {
        "name": "test_video.mp4",
        "video": "https://pomf2.lain.la/f/qqaemoh9.mp4"
      }
    ],
    "workflow": {
      "224": {
        "inputs": {
          "clip_name": "umt5_xxl_fp8_e4m3fn_scaled.safetensors",
          "type": "wan",
          "device": "default"
        },
        "class_type": "CLIPLoader",
        "_meta": {
          "title": "Load CLIP"
        }
      },
      "225": {
        "inputs": {
          "vae_name": "Wan2.1/wan_2.1_vae.safetensors"
        },
        "class_type": "VAELoader",
        "_meta": {
          "title": "Load VAE"
        }
      },
      "226": {
        "inputs": {
          "unet_name": "Wan2.2/Wan2_2-Animate-14B_fp8_scaled_e4m3fn_KJ_v2.safetensors",
          "weight_dtype": "default"
        },
        "class_type": "UNETLoader",
        "_meta": {
          "title": "Load Diffusion Model"
        }
      },
      "227": {
        "inputs": {
          "text": "A photorealistic video with visible lens flare and chromatic aberration showing Sadie01 a gorgeous redhead woman with light green eyes and pale skin, She is wearing a sleek navy blue bikini with a smooth finish that presses against her small sized breasts, she has a visible midriff and a hollow navel",
          "clip": [
            "224",
            0
          ]
        },
        "class_type": "CLIPTextEncode",
        "_meta": {
          "title": "Positive Prompt"
        }
      },
      "228": {
        "inputs": {
          "text": "Ëâ≤Ë∞ÉËâ≥‰∏ΩÔºåËøáÊõùÔºåÈùôÊÄÅÔºåÁªÜËäÇÊ®°Á≥ä‰∏çÊ∏ÖÔºåÂ≠óÂπïÔºåÈ£éÊ†ºÔºå‰ΩúÂìÅÔºåÁîª‰ΩúÔºåÁîªÈù¢ÔºåÈùôÊ≠¢ÔºåÊï¥‰ΩìÂèëÁÅ∞ÔºåÊúÄÂ∑ÆË¥®ÈáèÔºå‰ΩéË¥®ÈáèÔºåJPEGÂéãÁº©ÊÆãÁïôÔºå‰∏ëÈôãÁöÑÔºåÊÆãÁº∫ÁöÑÔºåÂ§ö‰ΩôÁöÑÊâãÊåáÔºåÁîªÂæó‰∏çÂ•ΩÁöÑÊâãÈÉ®ÔºåÁîªÂæó‰∏çÂ•ΩÁöÑËÑ∏ÈÉ®ÔºåÁï∏ÂΩ¢ÁöÑÔºåÊØÅÂÆπÁöÑÔºåÂΩ¢ÊÄÅÁï∏ÂΩ¢ÁöÑËÇ¢‰ΩìÔºåÊâãÊåáËûçÂêàÔºåÈùôÊ≠¢‰∏çÂä®ÁöÑÁîªÈù¢ÔºåÊùÇ‰π±ÁöÑËÉåÊôØÔºå‰∏âÊù°ËÖøÔºåËÉåÊôØ‰∫∫ÂæàÂ§öÔºåÂÄíÁùÄËµ∞",
          "clip": [
            "224",
            0
          ]
        },
        "class_type": "CLIPTextEncode",
        "_meta": {
          "title": "Negative Prompt"
        }
      },
      "255": {
        "inputs": {
          "shift": 8,
          "model": [
            "315",
            0
          ]
        },
        "class_type": "ModelSamplingSD3",
        "_meta": {
          "title": "Shift"
        }
      },
      "269": {
        "inputs": {
          "samples": [
            "387",
            0
          ],
          "vae": [
            "225",
            0
          ]
        },
        "class_type": "VAEDecode",
        "_meta": {
          "title": "VAE Decode"
        }
      },
      "311": {
        "inputs": {
          "image": "test_img.jpg"
        },
        "class_type": "LoadImage",
        "_meta": {
          "title": "Upload a reference image"
        }
      },
      "314": {
        "inputs": {
          "lora_name": "Wan2.2/Wan2.2-I2V-A14B-4steps-lora-rank64-Seko-V1-low_noise_model.safetensors",
          "strength_model": 1,
          "model": [
            "226",
            0
          ]
        },
        "class_type": "LoraLoaderModelOnly",
        "_meta": {
          "title": "LoraLoaderModelOnly"
        }
      },
      "315": {
        "inputs": {
          "lora_name": "Wan2.2/wan2.2_animate_14B_relight_lora_bf16.safetensors",
          "strength_model": 1,
          "model": [
            "314",
            0
          ]
        },
        "class_type": "LoraLoaderModelOnly",
        "_meta": {
          "title": "LoraLoaderModelOnly"
        }
      },
      "317": {
        "inputs": {
          "clip_name": "wan/clip_vision_h.safetensors"
        },
        "class_type": "CLIPVisionLoader",
        "_meta": {
          "title": "Load CLIP Vision"
        }
      },
      "324": {
        "inputs": {
          "seed": 43046390057774,
          "steps": 4,
          "cfg": 1,
          "sampler_name": "euler",
          "scheduler": "simple",
          "denoise": 1,
          "model": [
            "255",
            0
          ],
          "positive": [
            "370",
            0
          ],
          "negative": [
            "370",
            1
          ],
          "latent_image": [
            "370",
            2
          ]
        },
        "class_type": "KSampler",
        "_meta": {
          "title": "KSampler"
        }
      },
      "326": {
        "inputs": {
          "crop": "center",
          "clip_vision": [
            "317",
            0
          ],
          "image": [
            "311",
            0
          ]
        },
        "class_type": "CLIPVisionEncode",
        "_meta": {
          "title": "CLIP Vision Encode"
        }
      },
      "330": {
        "inputs": {
          "value": 720
        },
        "class_type": "PrimitiveInt",
        "_meta": {
          "title": "Video Width"
        }
      },
      "331": {
        "inputs": {
          "value": 1280
        },
        "class_type": "PrimitiveInt",
        "_meta": {
          "title": "Video Height"
        }
      },
      "365": {
        "inputs": {
          "keep_model_loaded": false,
          "individual_objects": false,
          "sam2_model": [
            "452",
            0
          ],
          "image": [
            "397",
            0
          ],
          "bboxes": [
            "451",
            3
          ]
        },
        "class_type": "Sam2Segmentation",
        "_meta": {
          "title": "Sam2Segmentation"
        }
      },
      "367": {
        "inputs": {
          "block_size": 32,
          "device": "gpu",
          "masks": [
            "457",
            0
          ]
        },
        "class_type": "BlockifyMask",
        "_meta": {
          "title": "Blockify Mask"
        }
      },
      "368": {
        "inputs": {
          "color": "0, 0, 0",
          "device": "gpu",
          "image": [
            "397",
            0
          ],
          "mask": [
            "367",
            0
          ]
        },
        "class_type": "DrawMaskOnImage",
        "_meta": {
          "title": "Draw Mask On Image"
        }
      },
      "370": {
        "inputs": {
          "width": [
            "330",
            0
          ],
          "height": [
            "331",
            0
          ],
          "length": [
            "383",
            0
          ],
          "batch_size": 1,
          "continue_motion_max_frames": 4097,
          "video_frame_offset": 0,
          "positive": [
            "227",
            0
          ],
          "negative": [
            "228",
            0
          ],
          "vae": [
            "225",
            0
          ],
          "clip_vision_output": [
            "326",
            0
          ],
          "reference_image": [
            "432",
            0
          ],
          "face_video": [
            "451",
            1
          ],
          "pose_video": [
            "456",
            0
          ],
          "background_video": [
            "368",
            0
          ],
          "character_mask": [
            "367",
            0
          ]
        },
        "class_type": "WanAnimateToVideo",
        "_meta": {
          "title": "WanAnimateToVideo"
        }
      },
      "383": {
        "inputs": {
          "value": [
            "418",
            6
          ]
        },
        "class_type": "PrimitiveInt",
        "_meta": {
          "title": "Video Length In Frames (auto generated)"
        }
      },
      "387": {
        "inputs": {
          "trim_amount": [
            "370",
            3
          ],
          "samples": [
            "324",
            0
          ]
        },
        "class_type": "TrimVideoLatent",
        "_meta": {
          "title": "TrimVideoLatent"
        }
      },
      "389": {
        "inputs": {
          "batch_index": [
            "370",
            4
          ],
          "length": 4096,
          "image": [
            "269",
            0
          ]
        },
        "class_type": "ImageFromBatch",
        "_meta": {
          "title": "ImageFromBatch"
        }
      },
      "397": {
        "inputs": {
          "image": [
            "412",
            0
          ]
        },
        "class_type": "ImagePass",
        "_meta": {
          "title": "ImagePass"
        }
      },
      "412": {
        "inputs": {
          "upscale_method": "lanczos",
          "width": [
            "330",
            0
          ],
          "height": [
            "331",
            0
          ],
          "crop": "center",
          "image": [
            "417",
            0
          ]
        },
        "class_type": "ImageScale",
        "_meta": {
          "title": "Upscale Image"
        }
      },
      "417": {
        "inputs": {
          "video": "test_video.mp4",
          "force_rate": 16,
          "force_size": "Disabled",
          "custom_width": 0,
          "custom_height": 0,
          "frame_load_cap": 81,
          "skip_first_frames": 0,
          "select_every_nth": 1,
          "format": "Wan"
        },
        "class_type": "VHS_LoadVideo",
        "_meta": {
          "title": "Upload a reference video"
        }
      },
      "418": {
        "inputs": {
          "video_info": [
            "417",
            3
          ]
        },
        "class_type": "VHS_VideoInfo",
        "_meta": {
          "title": "Video Info üé•üÖ•üÖóüÖ¢"
        }
      },
      "431": {
        "inputs": {
          "person_index": 0,
          "pose_kps": [
            "433",
            1
          ]
        },
        "class_type": "FaceMaskFromPoseKeypoints",
        "_meta": {
          "title": "Face Mask From Pose Keypoints"
        }
      },
      "432": {
        "inputs": {
          "base_resolution": 512,
          "padding": 235,
          "min_crop_resolution": 128,
          "max_crop_resolution": 512,
          "image": [
            "311",
            0
          ],
          "mask": [
            "431",
            0
          ]
        },
        "class_type": "ImageCropByMaskAndResize",
        "_meta": {
          "title": "Image Crop By Mask And Resize"
        }
      },
      "433": {
        "inputs": {
          "detect_hand": "disable",
          "detect_body": "disable",
          "detect_face": "enable",
          "resolution": 512,
          "bbox_detector": "yolox_l.onnx",
          "pose_estimator": "dw-ll_ucoco_384_bs5.torchscript.pt",
          "scale_stick_for_xinsr_cn": "disable",
          "image": [
            "311",
            0
          ]
        },
        "class_type": "DWPreprocessor",
        "_meta": {
          "title": "DWPose Estimator"
        }
      },
      "451": {
        "inputs": {
          "width": [
            "330",
            0
          ],
          "height": [
            "331",
            0
          ],
          "model": [
            "455",
            0
          ],
          "images": [
            "397",
            0
          ]
        },
        "class_type": "PoseAndFaceDetection",
        "_meta": {
          "title": "Pose and Face Detection"
        }
      },
      "452": {
        "inputs": {
          "model": "sam2.1_hiera_base_plus.safetensors",
          "segmentor": "video",
          "device": "cuda",
          "precision": "fp16"
        },
        "class_type": "DownloadAndLoadSAM2Model",
        "_meta": {
          "title": "(Down)Load SAM2Model"
        }
      },
      "455": {
        "inputs": {
          "vitpose_model": "vitpose_h_wholebody_model.onnx",
          "yolo_model": "yolov10m.onnx",
          "onnx_device": "CUDAExecutionProvider"
        },
        "class_type": "OnnxDetectionModelLoader",
        "_meta": {
          "title": "ONNX Detection Model Loader"
        }
      },
      "456": {
        "inputs": {
          "width": [
            "330",
            0
          ],
          "height": [
            "331",
            0
          ],
          "retarget_padding": 16,
          "body_stick_width": -1,
          "hand_stick_width": -1,
          "draw_head": "True",
          "pose_data": [
            "451",
            0
          ]
        },
        "class_type": "DrawViTPose",
        "_meta": {
          "title": "Draw ViT Pose"
        }
      },
      "457": {
        "inputs": {
          "expand": 10,
          "incremental_expandrate": 1,
          "tapered_corners": true,
          "flip_input": false,
          "blur_radius": 4,
          "lerp_alpha": 1,
          "decay_factor": 1,
          "fill_holes": false,
          "mask": [
            "365",
            0
          ]
        },
        "class_type": "GrowMaskWithBlur",
        "_meta": {
          "title": "Grow Mask With Blur"
        }
      },
      "462": {
        "inputs": {
          "frame_rate": 16,
          "loop_count": 0,
          "filename_prefix": "AnimateDiff",
          "format": "video/h264-mp4",
          "pix_fmt": "yuv420p",
          "crf": 19,
          "save_metadata": true,
          "trim_to_audio": false,
          "pingpong": false,
          "save_output": true,
          "no_preview": false,
          "images": [
            "389",
            0
          ],
          "audio": [
            "417",
            2
          ]
        },
        "class_type": "VHS_VideoCombine",
        "_meta": {
          "title": "Video Combine üé•üÖ•üÖóüÖ¢"
        }
      },
      "467": {
        "inputs": {
          "frame_rate": 16,
          "loop_count": 0,
          "filename_prefix": "AnimateDiff",
          "format": "video/h264-mp4",
          "pix_fmt": "yuv420p",
          "crf": 19,
          "save_metadata": true,
          "trim_to_audio": false,
          "pingpong": false,
          "save_output": true,
          "no_preview": false,
          "images": [
            "498",
            0
          ],
          "audio": [
            "417",
            2
          ]
        },
        "class_type": "VHS_VideoCombine",
        "_meta": {
          "title": "Video Combine üé•üÖ•üÖóüÖ¢"
        }
      },
      "474": {
        "inputs": {
          "pixels": [
            "389",
            0
          ],
          "vae": [
            "225",
            0
          ]
        },
        "class_type": "VAEEncode",
        "_meta": {
          "title": "VAE Encode"
        }
      },
      "475": {
        "inputs": {
          "lora_name": "Wan2.2/Wan2.2-T2V-A14B-4steps-lora-rank64-Seko-V1.1-low_noise_model.safetensors",
          "strength_model": 1,
          "model": [
            "479",
            0
          ]
        },
        "class_type": "LoraLoaderModelOnly",
        "_meta": {
          "title": "Lightx2v LoRA"
        }
      },
      "479": {
        "inputs": {
          "unet_name": "Wan2.2/wan2.2_t2v_low_noise_14B_fp16.safetensors",
          "weight_dtype": "default"
        },
        "class_type": "UNETLoader",
        "_meta": {
          "title": "Load Diffusion Model"
        }
      },
      "480": {
        "inputs": {
          "seed": 307619744968146,
          "steps": 4,
          "cfg": 1,
          "sampler_name": "euler",
          "scheduler": "simple",
          "denoise": 0.13,
          "model": [
            "475",
            0
          ],
          "positive": [
            "227",
            0
          ],
          "negative": [
            "228",
            0
          ],
          "latent_image": [
            "483",
            0
          ]
        },
        "class_type": "KSampler",
        "_meta": {
          "title": "KSampler"
        }
      },
      "481": {
        "inputs": {
          "samples": [
            "480",
            0
          ],
          "vae": [
            "225",
            0
          ]
        },
        "class_type": "VAEDecode",
        "_meta": {
          "title": "VAE Decode"
        }
      },
      "483": {
        "inputs": {
          "samples": [
            "387",
            0
          ],
          "mask": [
            "365",
            0
          ]
        },
        "class_type": "SetLatentNoiseMask",
        "_meta": {
          "title": "Set Latent Noise Mask"
        }
      },
      "485": {
        "inputs": {
          "ckpt_name": "rife49.pth",
          "clear_cache_after_n_frames": 5,
          "multiplier": 2,
          "fast_mode": false,
          "ensemble": true,
          "scale_factor": 1,
          "frames": [
            "506",
            0
          ]
        },
        "class_type": "RIFE VFI",
        "_meta": {
          "title": "RIFE VFI (recommend rife47 and rife49)"
        }
      },
      "488": {
        "inputs": {
          "batch_index": 0,
          "length": 1,
          "image": [
            "397",
            0
          ]
        },
        "class_type": "ImageFromBatch",
        "_meta": {
          "title": "ImageFromBatch"
        }
      },
      "489": {
        "inputs": {
          "batch_index": 0,
          "length": 1,
          "image": [
            "368",
            0
          ]
        },
        "class_type": "ImageFromBatch",
        "_meta": {
          "title": "ImageFromBatch"
        }
      },
      "494": {
        "inputs": {
          "seed": 604618084714910,
          "steps": 4,
          "cfg": 1,
          "sampler_name": "euler",
          "scheduler": "simple",
          "denoise": 0.05,
          "model": [
            "475",
            0
          ],
          "positive": [
            "499",
            0
          ],
          "negative": [
            "228",
            0
          ],
          "latent_image": [
            "497",
            0
          ]
        },
        "class_type": "KSampler",
        "_meta": {
          "title": "KSampler"
        }
      },
      "497": {
        "inputs": {
          "pixels": [
            "481",
            0
          ],
          "vae": [
            "225",
            0
          ]
        },
        "class_type": "VAEEncode",
        "_meta": {
          "title": "VAE Encode"
        }
      },
      "498": {
        "inputs": {
          "samples": [
            "494",
            0
          ],
          "vae": [
            "225",
            0
          ]
        },
        "class_type": "VAEDecode",
        "_meta": {
          "title": "VAE Decode"
        }
      },
      "499": {
        "inputs": {
          "text": "Sydney01, Realistic skin texture",
          "clip": [
            "224",
            0
          ]
        },
        "class_type": "CLIPTextEncode",
        "_meta": {
          "title": "Positive Prompt"
        }
      },
      "502": {
        "inputs": {
          "frame_rate": 16,
          "loop_count": 0,
          "filename_prefix": "AnimateDiff",
          "format": "video/h264-mp4",
          "pix_fmt": "yuv420p",
          "crf": 19,
          "save_metadata": true,
          "trim_to_audio": false,
          "pingpong": false,
          "save_output": true,
          "no_preview": false,
          "images": [
            "481",
            0
          ],
          "audio": [
            "417",
            2
          ]
        },
        "class_type": "VHS_VideoCombine",
        "_meta": {
          "title": "Video Combine üé•üÖ•üÖóüÖ¢"
        }
      },
      "504": {
        "inputs": {
          "frame_rate": 32,
          "loop_count": 0,
          "filename_prefix": "AnimateDiff",
          "format": "video/h264-mp4",
          "pix_fmt": "yuv420p",
          "crf": 19,
          "save_metadata": false,
          "trim_to_audio": false,
          "pingpong": false,
          "save_output": true,
          "no_preview": false,
          "images": [
            "485",
            0
          ],
          "audio": [
            "417",
            2
          ]
        },
        "class_type": "VHS_VideoCombine",
        "_meta": {
          "title": "Video Combine üé•üÖ•üÖóüÖ¢"
        }
      },
      "506": {
        "inputs": {
          "upscale_model": [
            "519",
            0
          ],
          "image": [
            "498",
            0
          ]
        },
        "class_type": "ImageUpscaleWithModel",
        "_meta": {
          "title": "Upscale Image (using Model)"
        }
      },
      "519": {
        "inputs": {
          "model_name": "2xLiveActionV1_SPAN_490000.pth"
        },
        "class_type": "UpscaleModelLoader",
        "_meta": {
          "title": "Load Upscale Model"
        }
      }
    }
  }
}